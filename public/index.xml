<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dencho</title>
    <link>//localhost:1313/</link>
      <atom:link href="//localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <description>Dencho</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>//localhost:1313/media/icon_hu1b14c2ed69a2f89c06f5de8cc0bd5fd1_301795_512x512_fill_lanczos_center_3.png</url>
      <title>Dencho</title>
      <link>//localhost:1313/</link>
    </image>
    
    <item>
      <title>Physics Based Procedural Animations [02]</title>
      <link>//localhost:1313/projects/experiments/2022/physicsbasedproceduralanimations02/</link>
      <pubDate>Wed, 16 Nov 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2022/physicsbasedproceduralanimations02/</guid>
      <description>&lt;p&gt;Calibrating the muscle joints on big Boss Character.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations02/XRLog_2022_917.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This character is for a physics based combat system I cant exactly talk about due to an NDA.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations02/XRLog_2022_911.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;For calibration and debugging physics I setup quick disposable testbed logic that might look pretty weird out of context.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations02/XRLog_2022_913.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;When done right, this guy will struggle to move objects with heavier mass than others. This is what it looks like when moving all objects with the same mass.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations02/XRLog_2022_917.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;And this is why we calibrate.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations02/XRLog_2022_939.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Terrain Practice [01]</title>
      <link>//localhost:1313/projects/experiments/2022/terrainpractice01/</link>
      <pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2022/terrainpractice01/</guid>
      <description>&lt;p&gt;Frustum Culling is a technique used in computer graphics to improve rendering performance by discarding objects that lie outside the viewing frustum.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/TerrainPractice01/XRLog_2022_905.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Frustum culling is a powerful optimization technique that balances computational cost with rendering efficiency. This is also a technique used in popular AAA titles like CyberPunk and Zero Dawn Horizon.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/TerrainPractice01/XRLog_2022_907.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Terrain Practice [01]</title>
      <link>//localhost:1313/projects/experiments/2022/terrainpractice02/</link>
      <pubDate>Fri, 11 Nov 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2022/terrainpractice02/</guid>
      <description>&lt;p&gt;Frustum Culling is a technique used in computer graphics to improve rendering performance by discarding objects that lie outside the viewing frustum.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/TerrainPractice01/XRLog_2022_905.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Frustum culling is a powerful optimization technique that balances computational cost with rendering efficiency. This is also a technique used in popular AAA titles like CyberPunk and Zero Dawn Horizon.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/TerrainPractice01/XRLog_2022_907.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Corrupted Realms</title>
      <link>//localhost:1313/projects/contracts/2022/corruptedrealms/</link>
      <pubDate>Sat, 22 Oct 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/contracts/2022/corruptedrealms/</guid>
      <description>&lt;!--TODO: Add a function or 2 from the tools inspector code and snap a pic of the custom inspector--&gt;
&lt;p&gt;A startup I worked for wanted a full blown MMORPG. Here is some of the work I did that im allowed to show.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CorruptedRealms/XRLog_2022_897.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This is one of my earliest projects involving Web3, at the time (2022) there was but a handful of blockchain SDKs that were compatible with Unity and C#. On top of all the Web3 functionality part of my job was to refine the combat and art workflow for maps.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Feature&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Invector Character System&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;A quick start to basic combat, but unacceptable for production.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Better Combat&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;The initial state of combat in the game was subpar at best.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;invector-woes&#34;&gt;Invector Woes&lt;/h4&gt;
&lt;p&gt;I&#39;m sure the Invector SDK is usable for a lot of projects. However I have never been more displeased by the code quality in the SDK. It makes me want to throw up and if I could go back to the start of development I would strongly recommend against using it. I ended reverse engineering parts of their character components so that performance would increase by 80%+ during stress testing. This is why it&#39;s not recommended to handle null or distance checks every frame. Shame shame.&lt;/p&gt;
&lt;h4 id=&#34;extending-combat&#34;&gt;Extending Combat&lt;/h4&gt;
&lt;p&gt;I started by overriding attack functions to tie into a custom sensor I made that detects other mob sensors. This was then used to input an relative &#34;intent&#34; direction the AI should use for the attack trajectory. I then combined all that with a custom physics PID controller I wrote a while back to make attacks apply forces to the attackers and defenders bodies. &lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CorruptedRealms/XRLog_2022_919.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Web3 Land Based Map System</title>
      <link>//localhost:1313/projects/contracts/2022/web3landmapsystem/</link>
      <pubDate>Sat, 22 Oct 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/contracts/2022/web3landmapsystem/</guid>
      <description>&lt;!--TODO: Add a function or 2 from the tools inspector code and snap a pic of the custom inspector--&gt;
&lt;p&gt;Contracted by a startup to RnD and produce a working prototype of an Interactive Map with overlaying hexagonal cells and dynamic states that change based on the live NFT metadata pulled from the blockchain.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/Web3LandMapSystem/XRLog_2022_897.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This is one of my earliest projects involving Web3, at the time (2022) there was but a handful of blockchain SDKs that were compatible with Unity and C#.&lt;/p&gt;
&lt;p&gt;This Map system need to be usable in a way that it helps you setup the map, and hold live data representations synced form the blockchain.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Feature&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;MapManager Component&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;In charge of loading terrain prefabs and settings relative to a scene Id, and contains CellData methods/data used to hold serialized data about points on the map.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Custom Inspectors&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Includes setup status among the needed controls to specify how to spawn a planar grid of cells across any number of terrains.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Automatic Serialization&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Hooks into Unity to serialize/deserialize data with the scene upon save reloading during development.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;CellData Saving and Loading&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;After initial setup, controls allow devs to save the current state of the maps cellData to a serialized array. During runtime upon connection to the blockchain, if supplied with a contract config, will pull the celldata bit by bit from the blockchain to override the default serialized data on the map. Only when data has been synced recently can users interact with cell states via a UI.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Dynamic CellData Status&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Upon user interaction, should display the current state of a NFTs land metadata.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Additional WebGL Branch&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;WebGL support for the map. With deep link for Web3 Wallet connection.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Asynchronous Code&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;The main thread only haults for saving files to disk. everything else used the async C# pattern to invoke logic overtime till the array queue is exhausted. Thanks to Cysharps UniTask plugin for supporting WebGL and unifying my asynchronous logic between platforms.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Frustrum Culling&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Occlusion Culling grass and other map objects based on what the camera sees. Much like the system from ZeroDawnHorizon and other AAA titles with big maps.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;AAA Cinemachine Camera System&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Uses Cinemachine, which is a popular AAA camera system part of the Unity registry that we can easily manipulate in code.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;rapid-prototyping&#34;&gt;Rapid Prototyping&lt;/h4&gt;
&lt;p&gt;It was important to save development time by exploring adaptable plugins from github and the asset store, that might give us a head start. After testing multiple grid based map plugins, we settled on one who&#39;s source code was extendable and well documented so we can adapt the plugin to work with NFT metadata.&lt;/p&gt;
&lt;p&gt;First step was to generate a map from an array of terrains, thus populating the serialized custom celldata thats compliant to the ERC-721 smart contract. Then a simple controller to navigate around the map, written from scratch using Cinemachine.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/Web3LandMapSystem/XRLog_2022_892.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;After a few months of work we had a working prototype that listed live NFT data synced from the blockchain.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/Web3LandMapSystem/XRLog_2022_899.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/Web3LandMapSystem/XRLog_2022_901.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This was the first version of the UX for the Map controls, they were revised later on.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/Web3LandMapSystem/XRLog_2022_903.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;A GUI to compliment the Map so the user can filter out thousands of NFT metadata to find one specifically.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/Web3LandMapSystem/XRLog_2022_909.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>NFT Artisan</title>
      <link>//localhost:1313/projects/experiments/2022/nftartisan/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2022/nftartisan/</guid>
      <description>&lt;!--TODO: Add a function or 2 from the tools inspector code and snap a pic of the custom inspector--&gt;
&lt;p&gt;This tool allowed the team to easily recreate NFT metadata and media from serialized data types in a Unity project, like an array of CellData or GameObjects.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/NFTArtisan/XRLog_2022_871.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;I learned alot about the growing standard that is NFT Metadata, how its imprinted onto the block chain via a smart contract, the requirements for batch uploading NFT metadata, and even interacting with smart contracts.&lt;/p&gt;
&lt;p&gt;Creating NFT media and metadata needs to be consistent in brand and format. This tool allows use to do just that after we make iterative changes to Land or NFT items in a Web3 enabled project.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Features&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Batch Generation&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Capable of generating over 100,000 NFT images or videos in one session with efficient batch processing.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Format Typing Support&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Supports PNG, JPG, and MP4 formats to accommodate various NFT media requirements.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Automatic Framing&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Operates independently on its own GameObject, allowing for movement and adjustment within the scene as needed.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;MapManager Integration&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Utilizes the CellData array from the MapManager component to generate &lt;code&gt;metadata.json&lt;/code&gt; files and media, processing each cell&amp;rsquo;s data based on its position and configured settings.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Recording Settings&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Offers highly adjustable recording settings to customize recording angles, durations (for videos), and formats, while being stored on a configurable scriptable object.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Scene Interaction&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Capable of handling large scale recordings and was tested with with over 100k CellData entries in the MapManager for comprehensive map coverage.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Dynamic Object Handling&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Links with an ItemDatabase or an array of Transforms to spawn instances at the recorder&amp;rsquo;s location, capturing necessary Metadata and Media.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Operational Versatility&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Functions both in and out of play mode, providing flexibility across different development stages.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Asynchronous Code&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;The main thread only haults for saving files to disk. everything else used the async C# pattern to invoke logic overtime till the array queue is exhausted.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Automated Cleanup&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Manages the cleanup of spawned instances post-recording to maintain scene integrity.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Export Functionality&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Exports generated Media and Metadata to specified folders, organizing assets for efficient access and use.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The end result is 2 folders full of fresh ready to upload NFT Media and Metadata.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/NFTArtisan/XRLog_2022_890.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Example of live NFTs using Metadata created from this tool.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/NFTArtisan/XRLog_2022_888.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/NFTArtisan/XRLog_2022_899.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>VFX Practice [07]</title>
      <link>//localhost:1313/projects/experiments/2022/vfxpractice07/</link>
      <pubDate>Thu, 10 Feb 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2022/vfxpractice07/</guid>
      <description>&lt;p&gt;A small experiment to create a reactive shadergraph with exposed properties that a custom controller can use to make the shader react to the beat of an audio clip.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice07/XRLog_2021_768.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;And a VFXGraph that controls particles to move along an array of world points over time. In this case I calculated a Hexagons orientation and size from a cells center position, then fed each corner to the VFXGraph via my custom tool.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice07/XRLog_2022_879.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Crypto Comedy Club</title>
      <link>//localhost:1313/projects/contracts/2022/cryptocomedyclub/</link>
      <pubDate>Wed, 05 Jan 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/contracts/2022/cryptocomedyclub/</guid>
      <description>&lt;p&gt;Contracted out by a small team with plans to launch a Comedy Club in the Metaverse tied to custom NFT metadata and the $LOL token.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2022_863_1.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;h2 id=&#34;devices-tested&#34;&gt;Devices tested:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Oculus Quest 1/2&lt;/li&gt;
&lt;li&gt;Pico 2/3&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Technologies Used --&gt;
&lt;h2 id=&#34;technologies-used&#34;&gt;Technologies used:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;VRoid SDK (Avatars)&lt;/li&gt;
&lt;li&gt;ReadyPlayerMe SDK (Avatars)&lt;/li&gt;
&lt;li&gt;OculusVR SDK&lt;/li&gt;
&lt;li&gt;UnityXR SDK&lt;/li&gt;
&lt;li&gt;PicoVR SDK&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Due to an NDA im not legally allowed to show the NFT portion of this project.&lt;/p&gt;
&lt;h4 id=&#34;the-blockchain&#34;&gt;The BlockChain&lt;/h4&gt;
&lt;p&gt;Implementing the blockchain took some work, however at the time we got it working due to an SDK called Moralis that was coming out at the time. Token and NFT transactions were able to take place using the connected Web3 wallet.&lt;/p&gt;
&lt;p&gt;One of the main features is being able to hop into a theatre and watch a comedian perform a live or recorded session with your friends.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2022_857.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;h4 id=&#34;physics-based-hand-tracked-posing&#34;&gt;Physics Based Hand-Tracked Posing&lt;/h4&gt;
&lt;p&gt;One of the main problems with HandTracking is the immersion break a user experiences when they reach out to grab a virtual object. Usually the virtual hands that mimic the real world hands end up clipping through the object the user is grabbing. This is my attempt to fix that.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2021_856.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;During my time at CCC I prototyped procedural hand poses when grabbing things with pure hand tracking. Each fingers Inverse Kinematic system is programmed to bend until a collider is detected.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2021_858.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2022_859_1.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2022_859_2.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2022_859_3.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;h4 id=&#34;working-with-readyplayerme-avatars&#34;&gt;Working with ReadyPlayerMe Avatars&lt;/h4&gt;
&lt;p&gt;The final PlayerController looked something like this with a live RPM Avatar.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2022_864.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2022_863_1.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;With both Hand and Controller tracked interaction!&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2022_863_2.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The UI eventually worked well enough.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2022_866.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Good enough to test out Peer2Peer Networking for the first time!&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2022_868.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;However there were some bugs involving Physics that didn&#39;t go well over the network.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2022_869.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;h4 id=&#34;audience-taming&#34;&gt;Audience Taming&lt;/h4&gt;
&lt;p&gt;Stress testing remote player count. Turns out even low quality avatars were such a big performance hit.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2021_846.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;So I just used voxelized avatars for the audience which solved the performance hit from a full house.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/CryptoComedyClub/XRLog_2021_848.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>New Test Project Post</title>
      <link>//localhost:1313/project/newpost/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/project/newpost/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/StaticStorage/Develop/Test/test0.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;











  





&lt;video autoplay loop  &gt;
  &lt;source src=&#34;https://raw.githack.com/Denchyaknow/StaticStorage/Develop/Test/test0.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;

</description>
    </item>
    
    <item>
      <title>XR Player Controller [05]</title>
      <link>//localhost:1313/projects/experiments/2021/xrplayercontroller05/</link>
      <pubDate>Sat, 15 May 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2021/xrplayercontroller05/</guid>
      <description>&lt;p&gt;Refining one of the first Prototypes to exist (in 2020) to contain a full body avatar and finger tracking.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_838.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;h2 id=&#34;devices-tested&#34;&gt;Devices tested:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Oculus Quest 1/2&lt;/li&gt;
&lt;li&gt;Pico 2/3&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Technologies Used --&gt;
&lt;h2 id=&#34;technologies-used&#34;&gt;Technologies used:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;VRoid SDK (Avatars)&lt;/li&gt;
&lt;li&gt;ReadyPlayerMe SDK (Avatars)&lt;/li&gt;
&lt;li&gt;OculusVR SDK&lt;/li&gt;
&lt;li&gt;UnityXR SDK&lt;/li&gt;
&lt;li&gt;PicoVR SDK&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First thing I did this round, was fail hard at using Mechanim Animator to handle my Hand Posing. Turns out its just easier and more performant to man handle hand posing with pure C#.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_729.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Semi working legs. Check.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_823.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;You know I had to make sure everything worked with physics. Just incase.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_828.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_830.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_849.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;h2 id=&#34;skeletal-mesh-orientation-mismatch-smom&#34;&gt;Skeletal Mesh Orientation Mismatch (S.M.O.M.)&lt;/h2&gt;
&lt;p&gt;S.M.O.M. happens when one mesh skeletal bone structure has incompatible orientations with another set of bones, leading to misalignment when trying to animate or manipulate them consistently.&lt;/p&gt;
&lt;p&gt;You can expect to run into SMOM when using ReadyPlayerMe avatars for a full body rig.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_832.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;However, SMOM is easily defeated with the use of my custom Hand Mapper.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_840.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The results, a full body XR controller that dynamically switches between hand and controller tracking. Not something you see often in 2021.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_836.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_838.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;And a simple voice plugin test to move the avatars facial blendshapes.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_842.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;During development, this gave me nightmares.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController05/XRLog_2021_844.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>AI Mob Controller [05]</title>
      <link>//localhost:1313/projects/experiments/2021/aimobcontroller05/</link>
      <pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2021/aimobcontroller05/</guid>
      <description>&lt;p&gt;This experiments goal was to iterate on my previous AI Controllers and refine the locomotion and procedural animations.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController05/XRLog_2021_802.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;I spent a good amount of focus on the making sure procedural animations work with physics.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController05/XRLog_2021_796.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController05/XRLog_2021_798.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController05/XRLog_2021_800.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The result allowed me to play an animation, and have physics forces affect it in a nice good lerpy way.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController05/XRLog_2021_800.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Next I applied the same system to another nonstandard skeleton.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController05/XRLog_2021_811.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController05/XRLog_2021_813.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController05/XRLog_2021_817.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController05/XRLog_2021_819.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController05/XRLog_2021_821.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Dynamic Collider System</title>
      <link>//localhost:1313/projects/experiments/2021/dynamiccollidersystem/</link>
      <pubDate>Wed, 05 May 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2021/dynamiccollidersystem/</guid>
      <description>&lt;p&gt;Colliders that transform with Physics.&lt;/p&gt; 
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/DynamicColliderSystem/XRLog_2021_764.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The goal of this system was to make hit events more generous relative to the movement of the rigidbody attached to the HurtBox.&lt;/p&gt; 
&lt;p&gt;To start I made some gizmos that show the thresholds of the dynamic settings you set in the component.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/DynamicColliderSystem/XRLog_2021_762.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This basically works as a Melee auto aim for a XR perspective. If the player thrusts a knife forward sometime VR depth can take getting used to, this makes it easier for players to hit something that might be a few inches father then perceived.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/DynamicColliderSystem/XRLog_2021_766.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;It actually works out pretty well, and I wrote it to be well performant. Just attach to a meshs child collider (box type) that has a rigidbody.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/DynamicColliderSystem/XRLog_2021_764.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>XR Bridge System</title>
      <link>//localhost:1313/projects/experiments/2021/xrbridgesystem/</link>
      <pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2021/xrbridgesystem/</guid>
      <description>&lt;p&gt;The goal of this experiment was to create a procedural dynamic map out of bridges and hub nodes of my own design.&lt;/p&gt; 
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRBridgeSystem/XRLog_2021_790.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;One problem I encountered was during the Spawning/Despawning of the bridges, framerate would drop on the Quest1 due to performance issues with colliders moving over time. This meant I could only make bridges so long before frames would skip.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRBridgeSystem/XRLog_2021_792.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;It worked well in theory but, in practice it&#39;s not that feasible on a low powered device like the Quest1.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRBridgeSystem/XRLog_2021_850.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>XR Magic System</title>
      <link>//localhost:1313/projects/experiments/2021/xrmagicsystem/</link>
      <pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2021/xrmagicsystem/</guid>
      <description>&lt;p&gt;I wanted a modular magic system that works with physics based grabbables.&lt;/p&gt; 
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRMagicSystem/XRLog_2021_741.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;So I made one, it has public methods that allow the user (mob or player) to charge mana into the magic spell that is being cast at the time of input.&lt;/p&gt; 
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRMagicSystem/XRLog_2021_739.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Once I got spawning pretty good, I added Telekinesis control, after a grabbable is spawned it will track the users appendage until mana is no longer being channeled into the spell.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRMagicSystem/XRLog_2021_741.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;I have no idea why I started making this, it just seemed fun. I hope to iterate upon it in the future.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AI Mob Controller [04]</title>
      <link>//localhost:1313/projects/experiments/2021/aimobcontroller04/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2021/aimobcontroller04/</guid>
      <description>&lt;p&gt;This experiments goal was to iterate on my previous AI Controllers and refine the combat system.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController04/XRLog_2021_771.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;I worked more on the combat skill pathing. It is now more dynamic while still using a physics PID controller to move the rigidbody via forces in additive manner.&lt;/p&gt;
&lt;p&gt;Both of these mobs use the same combat system, but one is tweaked to have a shorter travel path, with drag/angulardrag over time (set by a curve and multiplier) which allows me to create something like a bulletTime attack but in realtime.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController04/XRLog_2021_779.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This kind of system allows other physics objects to alter the pathing trajectory of the mob even while the skill is running.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController04/XRLog_2021_771.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Even works with drone like locomotion.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController04/XRLog_2021_804.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Discord RPC</title>
      <link>//localhost:1313/projects/experiments/2021/discordrpc/</link>
      <pubDate>Mon, 05 Apr 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2021/discordrpc/</guid>
      <description>&lt;p&gt;Custom Discord Plugin for Unity.&lt;/p&gt; 
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/DiscordRPC/XRLog_2021_727.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;A client requested integration with the Discord API, at the time there was no official Discord SDK in C#, I endedup using a Discord API C# wrapper I found on GitHub.&lt;/p&gt;
&lt;p&gt;Its just a simple plugin you can import, that hooks into a running discord client and shows a custom activity based on a scriptableObject config you can setup. It works in the Editor and during runtime and can be extended on to use analytical funnels.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/DiscordRPC/XRLog_2021_733.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Fun With Gizmos And Math</title>
      <link>//localhost:1313/projects/experiments/2021/funwithgizmosandmath/</link>
      <pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2021/funwithgizmosandmath/</guid>
      <description>&lt;p&gt;I create alot of small gizmos extensions, some of which for no reason and for fun.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/FunWithGizmosAndMath/XRLog_2021_816.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This was for debugging AI and Player Input Intent direction and overlaying angle thresholds to visualize the logic state during runtime.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/FunWithGizmosAndMath/XRLog_2022_915.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Look familiar?&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/FunWithGizmosAndMath/XRLog_2022_927.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>VFX Practice [06]</title>
      <link>//localhost:1313/projects/experiments/2021/vfxpractice06/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2021/vfxpractice06/</guid>
      <description>&lt;p&gt;More VFX practice so that I might one day be able to make a decent looking kamehameha.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice06/XRLog_2021_711.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice06/XRLog_2021_713.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;I made a custom Particle Effector that works with VFXGraph to control where the particles go in realtime.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice06/XRLog_2021_719.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice06/XRLog_2021_721.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;And a laser, cause why not?&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice06/XRLog_2021_731.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>AI Mob Controller [03]</title>
      <link>//localhost:1313/projects/experiments/2021/aimobcontroller03/</link>
      <pubDate>Wed, 10 Feb 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2021/aimobcontroller03/</guid>
      <description>&lt;p&gt;This experiments goal was to iterate on my previous AI Controllers and refine the spawning and path finding algorithms.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController03/XRLog_2021_696.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The models were provided by free assets on the Unity Asset Store.&lt;/p&gt;
&lt;p&gt;Created a Waypoint system that only allows one mob at a time to navigate to the point, the mobs automatically seek out point in a waypoint path that doesn&#39;t have its source/target points queued by another mob.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController03/XRLog_2021_688.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController03/XRLog_2021_709.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Testing out Ragdolling system for a nonstandart mesh rig.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController03/XRLog_2021_725.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;A Combat system that animated the Rigidbody with a Physics PID Controller to traverse a dynamic generated path, with adjustable curves/properties to change up how it ride the attack path.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController03/XRLog_2021_696.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>A* Map System</title>
      <link>//localhost:1313/projects/contracts/2021/astarmapsystem/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/contracts/2021/astarmapsystem/</guid>
      <description>&lt;p&gt;Contracted to make a Custom A* Map System.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AStarMapSystem/XRLog_2021_683.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;!--Link To Repo Here--&gt;
&lt;p&gt;The client requested a Custom Hex Tile Map System that had Methods to calculate the best path to take. It needed to be modular and flexible with any map size, and calculate pathing using an asynchronous pattern.&lt;/p&gt;
&lt;h3 id=&#34;the-a-algorithm&#34;&gt;The A* Algorithm&lt;/h3&gt;
&lt;p&gt;The A* (pronounced “A-star”) algorithm is a powerful pathfinding technique used in various fields of computer science. It offers completeness, optimality, and optimal efficiency.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A* is a graph traversal and pathfinding algorithm.&lt;/li&gt;
&lt;li&gt;Given a weighted graph, a source node, and a goal node, A* finds the shortest path (with respect to the given weights) from the source to the goal.&lt;/li&gt;
&lt;li&gt;It evaluates points using a heuristic value (also known as the H score), which estimates the distance from a node to the goal.&lt;/li&gt;
&lt;li&gt;A* combines both the movement cost (from the current point to its neighbors) and the heuristic value to guide its search.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AStarMapSystem/XRLog_2021_685.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;It even came with a Custom Editor Tool I made to help simulate the pathing in and outside of PlayMode.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AStarMapSystem/XRLog_2021_687.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>AI Mob Controller [02]</title>
      <link>//localhost:1313/projects/experiments/2021/aimobcontroller02/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2021/aimobcontroller02/</guid>
      <description>&lt;p&gt;This experiment is mainly focused on ground based AI designed to work with a XR Player Controller.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController02/XRLog_2021_641.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;First I wrote my own PID controller to control a Rigidbody via physics to match a point in world space with gravity accounted for.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController02/XRLog_2021_643.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController02/XRLog_2021_645.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController02/XRLog_2021_653.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Combat Testing. Just going to throw a rock at it.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController02/XRLog_2021_636.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController02/XRLog_2021_641.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Stress-testing spawn mechanics.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController02/XRLog_2020_612.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController02/XRLog_2021_630.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Horror Style Mobs</title>
      <link>//localhost:1313/projects/contracts/2021/smartvendingmachine/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/contracts/2021/smartvendingmachine/</guid>
      <description>&lt;p&gt;Contracted to make a &#34;Smart&#34; Vending Machine feature designed to work with VR Players.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/SmartVendingMachine/XRLog_2021_671.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;NDA Prevents me from showing the UI or final outcome of the feature.&lt;/p&gt;
&lt;p&gt;The goal was to create a Vending Machine that had a would automatically adjust to the VR Players Height via a Robot Arm controlled by Inverse Kinematics.&lt;/p&gt;
&lt;p&gt;The teams technical artist provided the Vending Machine mesh with armature for the screens housing. The first step was connect the bones to a simple Inverse Kinematic script.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/SmartVendingMachine/XRLog_2021_657.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Next I see how it targets the Players Head transform.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/SmartVendingMachine/XRLog_2021_664.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;With a bit of some C# magic, the Arm for the screen will extend out to any nearby Players Head transform. When the target is out of range for x+ seconds, the screen will retract back into the machine.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/SmartVendingMachine/XRLog_2021_671.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/SmartVendingMachine/XRLog_2021_673.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>GameJam [01]</title>
      <link>//localhost:1313/projects/experiments/2020/gamejam01/</link>
      <pubDate>Fri, 12 Jun 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/gamejam01/</guid>
      <description>&lt;p&gt;This GameJams theme was the exploration of destructible objects using magic.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_279.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The first goal was to code out a Telekinesis framework that uses a signle input to lift and throw physics bodies&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_234.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_237.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Next was to make the same TK system affect structures connected by configurable joints.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_240.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_243.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_260.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Next I wrote a tool to automagically detect child rigidbodies and attach recursive connecting configurable joints to each parent/child combo according to a configuration set before runtime. Pain to write, but satisfying to test.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_263.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_269.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_272.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Next came alternate TK abilities and properties to achieve different features from the same framework.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_279.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_282.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_285.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_288.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_291.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Sadly we ran out of time, I learned in the future to make sure to work with a more capable team.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/GameJam01/XRLog_2020_294.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>VFX Practice [05]</title>
      <link>//localhost:1313/projects/experiments/2020/vfxpractice05/</link>
      <pubDate>Wed, 13 May 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/vfxpractice05/</guid>
      <description>&lt;p&gt;Rhythm based VFX, A simple test of animating VFX components to the beat, volume, and onset of an analyzed audio clip.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice05/XRLog_2020_500.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Turns out everything works which means I can make a rhythm game now.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice05/XRLog_2020_521.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice05/XRLog_2020_524.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Next I&#39;ll try making this work with VFXGraph and ShaderGraph.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Physics Based Exo-Skeleton Arms</title>
      <link>//localhost:1313/projects/experiments/2020/physicsbasedexoskeletonarms/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/physicsbasedexoskeletonarms/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedExoSkeletonArms/XRLog_2020_001.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;I believe VR can be a cheap and effective way to test out ideas. On day I wondered how fun it would be to give the user giant Exo Arms.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media1&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedExoSkeletonArms/XRLog_2020_005.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This crude prototype gave me decent understanding one how it would feel for one arm anyway.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>XR Chemistry Framework</title>
      <link>//localhost:1313/projects/experiments/2020/xrchemistryframework/</link>
      <pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/xrchemistryframework/</guid>
      <description>&lt;p&gt;I was contacted and contracted out by a School District Manager looking for ways to Adapt XR as a means for kids to learn remotely in a more immersive way.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media1&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_400.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The things I can show from this project are limited due to an NDA&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_391.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The main goal of this prototype was to create a UI capable of spawning Chemistry related instances of Molecule models and allow interaction with them for lecturing purposes in a Teacher to Student relationship.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media1&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_394.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;As the project was already 12 months into development at the time I joined, I had to work well with the existing team to know where to put my code and to make sure there were no conflicts with existing UX components&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_397.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Prototyping a way you can move molecules with hand tracking, even under low lighting.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_559.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The idea was that if a hand pinches near the center of a molecule group, the molecule with use the relative index finger as a Anchor with a Kinematic PID controller handling the positioning.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_563.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;First I start with a Transform Marker in the form of a filling sprite, that acts as the target position for the molecule.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_570.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Now just a simple controller that takes account of the distance between the current and target points. Its always fun to see how well I can write something the first time.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_573.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_576.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Adding a Highlight to show when a molecule is a valid target to grab.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_596.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Then I made similar control method for orientation&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_599.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_602.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The UX needs to be cleaned up a bit, but all in all it was a success.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRChemistryFramework/XRLog_2020_605.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>VFX Practice [04]</title>
      <link>//localhost:1313/projects/experiments/2020/vfxpractice04/</link>
      <pubDate>Mon, 13 Apr 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/vfxpractice04/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice04/XRLog_2020_164.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This was made using ShaderGraph for Unity and some C# elbow grease.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice04/XRLog_2020_167.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice04/XRLog_2020_170.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice04/XRLog_2020_174.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice04/XRLog_2020_158.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice04/XRLog_2020_177.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>XR Player Controller [04]</title>
      <link>//localhost:1313/projects/experiments/2020/xrplayercontroller04/</link>
      <pubDate>Fri, 10 Apr 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/xrplayercontroller04/</guid>
      <description>&lt;p&gt;Refining one of the first Prototypes to exist (in 2020) to contain a full body avatar and finger tracking.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_340.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;h2 id=&#34;devices-tested&#34;&gt;Devices tested:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Oculus CV1&lt;/li&gt;
&lt;li&gt;Oculus Quest 1&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Technologies Used --&gt;
&lt;h2 id=&#34;technologies-used&#34;&gt;Technologies used:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;VRoid SDK (Avatars)&lt;/li&gt;
&lt;li&gt;OculusVR SDK&lt;/li&gt;
&lt;li&gt;UnityXR SDK&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I was one of the first developers in the industry to achieve fullbody avatars working with finger tracking. Once you get past the hurdle of different bone orientations the rest is pretty simple, I was just a dev with just enough free time to actually do it.&lt;/p&gt;
&lt;h2 id=&#34;skeletal-mesh-orientation-mismatch-smom&#34;&gt;Skeletal Mesh Orientation Mismatch (S.M.O.M.)&lt;/h2&gt;
&lt;p&gt;S.M.O.M. happens when one mesh skeletal bone structure has incompatible orientations with another set of bones, leading to misalignment when trying to animate or manipulate them consistently. I am no longer afraid of SMOM and I am going to use one of the most common Avatars available to developers, Unity-Chan&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_337.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Using this formula here I was able to avoid this issue, however the custom tool I made requires a basic understanding of how Quaternions work.&lt;/p&gt;
&lt;!--TODO: Show Math Formula and Code Snippet here--&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_340.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Testing UI Ray Pointers with Finger Tracking.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_349.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_353.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_356.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_359.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_362.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;I wrote an algorithm that tracks and predicts the tracked hands position and velocity. My goal was to Handle the case of when Hands overlap causing hand tracking to be lost due to occlusion. This algorithm understands when the Hands become occluded and attempts to predict and move the hands relative to their original trajectory at the time of occlusion.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_367.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;You can see that since I am simply lerping the predicted target IK position of each hand, there is no teleporting going on when hand tracking resumes from being occluded.&lt;/p&gt;
&lt;p&gt;When Hand tracking quality becomes low, mapping of the fingers halt and then blend to the target orientations once tracking quality is high again.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_370.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Testing relations with Physics based Grabbables when a Button magically resets an objects transform.&lt;/p&gt; 
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_373.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;When this Physics button is pressed the Cubes Reset.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_376.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_379.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Nothing much to take from this other than knowing the rigidbody wont explode the Players rigidbody in some way.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_382.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_385.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_388.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;There were a few setup issues with the relative Rig height. Nothing I can&#39;t handle.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_343.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController04/XRLog_2020_346.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Physics Based Exo-Skeleton Arms</title>
      <link>//localhost:1313/projects/experiments/2020/physicsbasedlocomotion/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/physicsbasedlocomotion/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedLocomotion/XRLog_2020_195.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This was one of the most difficult prototypes for my skill level at the time. The prototype code would need to be refactored before I would attempt putting it into beta testing.&lt;/p&gt;
&lt;p&gt;Part of the math I needed to master was how 3D normals and reflections are calculated.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media1&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedLocomotion/XRLog_2020_180.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Yes its a Sphere for now, but keep in mind this prototype is using RigidBodies and a Velocity PID controller that I wrote to move the body via Physics.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media1&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedLocomotion/XRLog_2020_180.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Testing Variable Properties out.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media1&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedLocomotion/XRLog_2020_192.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>VFX Practice [03]</title>
      <link>//localhost:1313/projects/experiments/2020/vfxpractice03/</link>
      <pubDate>Fri, 13 Mar 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/vfxpractice03/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice03/XRLog_2020_154.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This was made using VFXGraph for Unity.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice03/XRLog_2020_151.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Physics Based Buttons [02]</title>
      <link>//localhost:1313/projects/contracts/2020/xrphysicsbasedbuttons02/</link>
      <pubDate>Wed, 11 Mar 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/contracts/2020/xrphysicsbasedbuttons02/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedButtons02/XRLog_2020_580.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Another contract to improve front-end buttons. NDA prevents me from showing the exact implementation of the new buttons but, I am allowed to show them off on my own Menu Prototype.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedButtons02/XRLog_2020_583.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedButtons02/XRLog_2020_587.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedButtons02/XRLog_2020_590.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedButtons02/XRLog_2020_593.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>XR Player Controller [03]</title>
      <link>//localhost:1313/projects/experiments/2020/xrplayercontroller03/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/xrplayercontroller03/</guid>
      <description>&lt;p&gt;One of the earliest prototypes to exist at the time (2020) that I know of, to contain a full body avatar and finger tracking.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController03/XRLog_2020_201.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;h2 id=&#34;devices-tested&#34;&gt;Devices tested:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Oculus CV1&lt;/li&gt;
&lt;li&gt;Oculus Quest 1&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Technologies Used --&gt;
&lt;h2 id=&#34;technologies-used&#34;&gt;Technologies used:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Vroid SDK (Avatars)&lt;/li&gt;
&lt;li&gt;Oculus VR SDK&lt;/li&gt;
&lt;li&gt;UnityXR SDK&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I was one of the first developers in the industry to achieve fullbody avatars working with finger tracking. Once you get past the hurdle of different bone orientations the rest is pretty simple, I was just a dev with just enough free time to actually do it.&lt;/p&gt;
&lt;h2 id=&#34;skeletal-mesh-orientation-mismatch-smom&#34;&gt;Skeletal Mesh Orientation Mismatch (S.M.O.M.)&lt;/h2&gt;
&lt;p&gt;S.M.O.M. happens when one mesh skeletal bone structure has incompatible orientations with another set of bones, leading to misalignment when trying to animate or manipulate them consistently. It’s essential to ensure that both hand meshes follow the same bone orientation conventions to avoid issues during animation and rigging processes. However sometimes this cant be avoided when sourcing from different third parties, in this case I had trouble aligning VRoid Hand Skeleton to match with the Hand Skeleton from the OVR SDK used for hand tracking.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController03/XRLog_2020_050.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;h2 id=&#34;bypassing-smom&#34;&gt;Bypassing S.M.O.M.&lt;/h2&gt;
&lt;p&gt;When dealing with skeletal mesh orientation mismatches between two hand skeletons, you can use a transformation formula to align their orientations. This approach allows you to transfer the orientation from one hand to another, even if they initially have different orientations.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController03/XRLog_2020_198.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Using this formula here I was able to avoid this issue, however the custom tool I made requires a basic understanding of how Quaternions work.&lt;/p&gt;
&lt;!--TODO: Show Math Formula and Code Snippet here--&gt;
&lt;p&gt;Using a Homemade VRoid Avatar, which uses a Universal Skeleton Armature. This is what happened when trying to sync up rotations from OVR custom hand skeleton to the VRoids hand.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController03/XRLog_2020_201.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Locomotion Testing&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController03/XRLog_2020_213.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Locomotion Jumping with Physics still needs work.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController03/XRLog_2020_216.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController03/XRLog_2020_222.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>AI Mob Controller [01]</title>
      <link>//localhost:1313/projects/experiments/2020/aimobcontroller01/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/aimobcontroller01/</guid>
      <description>&lt;p&gt;The goal of this experiment was to learn what it takes to create an AI that operates within perspective of a XRPlayerControllers camera view.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController01/XRLog_2020_414.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;First I wrote my own PID controller to control a Drones Rigidbody via physics to match a point in world space.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController01/XRLog_2020_414.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController01/XRLog_2020_417.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Adjusting the variables allowed to to appear more smooth and animated.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController01/XRLog_2020_420.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController01/XRLog_2020_423.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Different properties can lead to different behaviors.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController01/XRLog_2020_426.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Now we give it a gun. For learning.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController01/XRLog_2020_407.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Make sure it knows how to shoot. With even the recoil effecting the PID controller.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController01/XRLog_2020_433.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController01/XRLog_2020_436.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController01/XRLog_2020_440.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This can get pretty chaotic but, its good to know how many bodies I can simulate at a given time when you consider theres a PID controller for each Rigidbody.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/AIMobController01/XRLog_2020_443.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Physics Based Procedural Animations [01]</title>
      <link>//localhost:1313/projects/experiments/2020/physicsbasedproceduralanimations01/</link>
      <pubDate>Tue, 18 Feb 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/physicsbasedproceduralanimations01/</guid>
      <description>&lt;p&gt;I love working on physics based animations.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations01/XRLog_2020_308.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;I love procedural animations, most system use Inverse Kinematics to accomplish this, as do my systems. However I wanted to take it to the next level and allow dynamic blending between Inverse Kinematics and Physics Simulations.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations01/XRLog_2020_311.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This should allow my to play a Humanoid animation on the skeleton while still applying IK to the bones, and lerp between a &#34;Live&#34; and &#34;Ragdoll&#34; state for the characters physics body.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations01/XRLog_2020_314.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations01/XRLog_2020_317.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations01/XRLog_2020_320.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Its far from perfect and I still need to find a use case but, its still fun to look at.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations01/XRLog_2020_323.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations01/XRLog_2020_326.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedProceduralAnimations01/XRLog_2020_329.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>VFX Graph Projectile [02]</title>
      <link>//localhost:1313/projects/experiments/2020/vfxgraphprojectile02/</link>
      <pubDate>Sat, 15 Feb 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/vfxgraphprojectile02/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXGraphProjectile02/XRLog_2020_138.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;One of my goals was to make the projectile a grabbable with dynamic states, meaning it could be held and thrown like a grenade, or charged and shot like a plasma blast.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXGraphProjectile02/XRLog_2020_136.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Avatars provided by the VRoid Hub.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXGraphProjectile02/XRLog_2020_141.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This allowed me to test out some Combat simulations&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXGraphProjectile02/XRLog_2020_147.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>VFX Practice [02]</title>
      <link>//localhost:1313/projects/experiments/2020/vfxpractice02/</link>
      <pubDate>Thu, 13 Feb 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/vfxpractice02/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice02/XRLog_2020_129.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This was made using VFXGraph for Unity.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice02/XRLog_2020_126.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice02/XRLog_2020_132.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Physics Based Buttons [01]</title>
      <link>//localhost:1313/projects/contracts/2020/xrphysicsbasedbuttons01/</link>
      <pubDate>Tue, 11 Feb 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/contracts/2020/xrphysicsbasedbuttons01/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedButtons01/XRLog_2020_067.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Contract to improve front-end buttons. NDA prevents me from showing the finished prototype.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/PhysicsBasedButtons01/XRLog_2020_070.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>XR Player Controller [02]</title>
      <link>//localhost:1313/projects/experiments/2020/xrplayercontroller02/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/xrplayercontroller02/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_076.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;h2 id=&#34;devices-tested&#34;&gt;Devices tested:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Oculus CV1&lt;/li&gt;
&lt;li&gt;Oculus Quest 1&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Technologies Used --&gt;
&lt;h2 id=&#34;technologies-used&#34;&gt;Technologies used:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Vroid SDK (Avatars)&lt;/li&gt;
&lt;li&gt;Oculus VR SDK&lt;/li&gt;
&lt;li&gt;UnityXR SDK&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This was my second attempt at a XR Player Controller. My main goal here was to make sure I can modularize components while solidifying most of the prototype code.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_079.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The Avatar was home made this time using a base Vroid from Vroid Studio and Decimating it in Blender for low poly testing.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_083.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;I wrote the Grabbable components you see here, in order to make it work with physics.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_086.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Held hand poses still need some work.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_092.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_095.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_098.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Testing some facial blendshapes out.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_073.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_113.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_144.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Jumping still needs work.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media1&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_052.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;HandTracking was a complete failure as different avatar rigs have skeleton bones that use a different axis orientation. So one can not simply match up rotations 1:1 unless all bones use the same orientation axis.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media1&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController02/XRLog_2020_050.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>VFX Graph Projectile [01]</title>
      <link>//localhost:1313/projects/experiments/2020/vfxgraphprojectile01/</link>
      <pubDate>Wed, 15 Jan 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/vfxgraphprojectile01/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXGraphProjectile01/XRLog_2020_040.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;I made this projectile using a home made VFX graph, and some C# elbow grease to make the projectile act like its part of a physics based charging system.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXGraphProjectile01/XRLog_2020_037.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Shooting some boxes. Yes I am aware im shooting the projectile out of a scope.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXGraphProjectile01/XRLog_2020_027.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;The idea behind this kind of system is the modularity of the script I made allowing it to work with any VFXGraph setup with the right event and exposed properties.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXGraphProjectile01/XRLog_2020_046.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Avatars provided by the VRoid Hub.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXGraphProjectile01/XRLog_2020_048.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>VFX Practice [01]</title>
      <link>//localhost:1313/projects/experiments/2020/vfxpractice01/</link>
      <pubDate>Mon, 13 Jan 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/vfxpractice01/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice01/XRLog_2020_107.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Some custom code to rotate simulated points and emit particles offset via some maths.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice01/XRLog_2020_101.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice01/XRLog_2020_104.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;This was made using VFXGraph for Unity.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/VFXPractice01/XRLog_2020_110.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>XR Player Controller [01]</title>
      <link>//localhost:1313/projects/experiments/2020/xrplayercontroller01/</link>
      <pubDate>Fri, 10 Jan 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/experiments/2020/xrplayercontroller01/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController01/XRLog_2020_003.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;h2 id=&#34;devices-tested&#34;&gt;Devices tested:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Oculus CV1&lt;/li&gt;
&lt;li&gt;Oculus Quest 1&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Technologies Used --&gt;
&lt;h2 id=&#34;technologies-used&#34;&gt;Technologies used:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;UMA2 (Avatars)&lt;/li&gt;
&lt;li&gt;Oculus VR SDK&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This was my first attempt at a XR Player Controller. Starting small my goal was to just get each limb lined up with basic controller based Hand Poses working.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;handWaving&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController01/XRLog_2020_003.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Clothes Placements and RayPointers&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;rayPointers&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController01/XRLog_2020_007.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;My own Custom Grabbables and my try at 2 handed grabbing.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;twoHandedGrabbables&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController01/XRLog_2020_009.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Writing my own Locomotion was great practice. More work needed to be done on the jumping.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;locomotion&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/XRPlayerController01/XRLog_2020_011.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>Horror Style Mobs</title>
      <link>//localhost:1313/projects/contracts/2020/horrorstylemobs/</link>
      <pubDate>Sun, 05 Jan 2020 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/projects/contracts/2020/horrorstylemobs/</guid>
      <description>&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/HorrorStyleMobs/XRLog_2020_061.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;
&lt;p&gt;Contract to add horror themed mobs to a VR experience. NDA prevents me from showing the finished prototype.&lt;/p&gt;
&lt;p&gt;I used an asset pack and custom texture from a FilterForge plugin.&lt;/p&gt;
&lt;div class=&#34;video_thing&#34;&gt;
    &lt;video muted autoplay=&#34;&#34; name=&#34;media1&#34; loop=&#34;&#34;&gt;&lt;source src=&#34;https://raw.githack.com/Denchyaknow/GitSite_Dencho/Develop/assets/media/projects/HorrorStyleMobs/XRLog_2020_064.webm&#34; type=&#34;video/mp4&#34;&gt;&lt;/video&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title></title>
      <link>//localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/about/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>//localhost:1313/home/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>//localhost:1313/home/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
